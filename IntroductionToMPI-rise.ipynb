{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Message Passing Interface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is MPI?\n",
    "\n",
    "* Message Passing Interface\n",
    "  * Most useful on distributed memory machines\n",
    "  * The *de facto standard* parallel programming interface\n",
    "  \n",
    "* Many implementations, interfaces in C/C++, Fortran, Python via MPI4Py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Message Passing Paradigm\n",
    "\n",
    "* A parallel MPI program is launched as separate processes (tasks), each with thier own address space.\n",
    "  * Requires partitioning data across tasks.\n",
    "* **Data is explicitly** moved from task to task \n",
    "  * A task accesses the data of another task through a transaction called \"message passing\" in which a copy of the\n",
    "data (message) is transferred (passed) from one task to another.\n",
    "* There are two classes of message passing\n",
    "  * **Point-to-point** involve only two tasks\n",
    "  * **Collective messages** involve a set of tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MPI4Py\n",
    "\n",
    " * MPI4Py provides an interface very similar to the MPI standard C++ interface\n",
    " * You can communicate Python objects.\n",
    " * What you may lose in performance, you gain in shorter development time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Communicators\n",
    "\n",
    " * MPI uses communicator objects to identify a set of processes which communicate only within their set.\n",
    " * `MPI_COMM_WORLD` is defined as all processes (ranks) of your job.\n",
    " * Usually required for most MPI calls \n",
    " * Rank\n",
    "   * Unique process ID within a communicator\n",
    "   * Assigned by the system when the process initalizes\n",
    "   * Used to specify sources and destinations of messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%file hello.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "print(\"Hello, World! My rank is: \" + str(comm.rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!mpiexec -np 2 python hello.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Point-to-Point Communication\n",
    "\n",
    "Sending data from one point (process/task) to another point (process/task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%file send_recv.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "size = comm.size\n",
    "v = numpy.array([rank] * 10,dtype=float)\n",
    "if comm.rank == 0:\n",
    "    comm.send(v, dest = (rank + 1) % size)\n",
    "if comm.rank > 0:\n",
    "    data = comm.recv(source = (rank - 1) % size)\n",
    "    comm.send(v, dest = (rank + 1) % size)\n",
    "if comm.rank == 0:\n",
    "    data = comm.recv(source = size - 1)\n",
    "print(\"My rank is \" + str(rank) + \"\\n I received this:\\n\" + str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!mpiexec -np 2 python send_recv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Collective Communication\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr style=\"background-color:transparent\">\n",
    "        <td><img src=\"images/collective_comm.png\" width=400/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "[Image Source](https://computing.llnl.gov/tutorials/parallel_comp/images/collective_comm.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Scatter\n",
    "\n",
    "Rank 0 acts as a leader, creating a list and `scatter`ing it out to all\n",
    "ranks evenly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%file scatter.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "sendbuf = []\n",
    "comm = MPI.COMM_WORLD\n",
    "if comm.rank == 0:\n",
    "    m = numpy.random.randn(comm.size, comm.size)\n",
    "    print(\"Original array on rank 0:\\n\" + str(m))\n",
    "    sendbuf = m\n",
    "v = comm.scatter(sendbuf, root=0)\n",
    "print(\"I got this array:\\n\" + str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!mpiexec -np 2 python scatter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gather\n",
    "\n",
    "`gather` is a command that collects results from all processes into a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%file gather.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "comm = MPI.COMM_WORLD\n",
    "sendbuf = []\n",
    "root = 0\n",
    "if comm.rank == 0:\n",
    "    m = numpy.array(range(comm.size * comm.size), dtype=float)\n",
    "    m.shape=(comm.size, comm.size)\n",
    "    print(\"Original array on rank 0:\\n\" + str(m))\n",
    "    sendbuf = m\n",
    "    \n",
    "v = comm.scatter(sendbuf, root=0)\n",
    "print(\"I got this array:\\n\" + str(v))\n",
    "v = v * v\n",
    "recvbuf = comm.gather(v, root=0)\n",
    "if comm.rank == 0:\n",
    "    print(\"New array on rank 0:\\n\" + str(numpy.array(recvbuf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!mpiexec -np 2 python gather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Broadcast\n",
    "\n",
    "`bcast` sends a single object to every process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%file broadcast.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "comm = MPI.COMM_WORLD\n",
    "sendbuf = []\n",
    "if comm.rank == 0:\n",
    "    m = numpy.array(range(comm.size * comm.size), dtype=float)\n",
    "    m.shape=(comm.size, comm.size)\n",
    "    print(\"Original array on rank 0:\\n\" + str(m))\n",
    "    sendbuf = m\n",
    "    \n",
    "v = comm.scatter(sendbuf, root=0)\n",
    "print(\"I got this array:\\n\" + str(v))\n",
    "v = v * v\n",
    "recvbuf = comm.gather(v, root=0)\n",
    "if comm.rank == 0:\n",
    "    print(\"New array on rank 0:\\n\" + str(numpy.array(recvbuf)))\n",
    "if MPI.COMM_WORLD.rank == 0:\n",
    "    sendbuf = \"Done!\"\n",
    "recvbuf = MPI.COMM_WORLD.bcast(sendbuf, root=0)\n",
    "print(recvbuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!mpiexec -np 2 python broadcast.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Reduce\n",
    "\n",
    "`reduce` performs a parallel reduction operation\n",
    " * The default is summation, but many other operators are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%file reduce.py\n",
    "#!/usr/bin/env python\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "comm = MPI.COMM_WORLD\n",
    "sendbuf = []\n",
    "if comm.rank == 0:\n",
    "    m = numpy.array(range(comm.size * comm.size), dtype=numpy.float)\n",
    "    m.shape=(comm.size, comm.size)\n",
    "    print(\"Original array on rank 0:\\n\" + str(m))\n",
    "    sendbuf = m\n",
    "v = comm.scatter(sendbuf, root=0)\n",
    "print(\"I got this array:\\n\" + str(v))\n",
    "recvbuf = comm.reduce(v, root=0)\n",
    "if comm.rank == 0:\n",
    "    total_sum = numpy.sum(numpy.array(recvbuf))\n",
    "    print(\"New array on rank 0:\\n\" + str(total_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!mpiexec -np 2 python reduce.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "* http://mpi4py.scipy.org/docs/usrman/index.html\n",
    "\n",
    "* https://computing.llnl.gov/tutorials/parallel_comp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "function hideElements(elements, start) {\n",
       "    for(var i = 0, length = elements.length; i < length;i++) {\n",
       "        if(i >= start) {\n",
       "            elements[i].style.display = \"none\";\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "var prompt_elements = document.getElementsByClassName(\"prompt\");\n",
       "hideElements(prompt_elements, 0)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "function hideElements(elements, start) {\n",
    "    for(var i = 0, length = elements.length; i < length;i++) {\n",
    "        if(i >= start) {\n",
    "            elements[i].style.display = \"none\";\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "var prompt_elements = document.getElementsByClassName(\"prompt\");\n",
    "hideElements(prompt_elements, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "livereveal": {
   "autolaunch": true,
   "footer": "<img src='images/UT.png' width='220'>",
   "progress": true,
   "scroll": true,
   "theme": "simple"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
